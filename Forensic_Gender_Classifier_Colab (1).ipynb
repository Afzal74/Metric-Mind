{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ ML-Based Forensic Gender Classifier\n",
    "## Team Metric Mind - VTU CSE Project\n",
    "\n",
    "**Using 15 Mandibular Measurements (No Serial No./ID)**\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Model Information:\n",
    "- **Best Model:** Logistic Regression\n",
    "- **Accuracy:** 75.00%\n",
    "- **Features:** 15 mandibular measurements\n",
    "- **Dataset:** 156 samples (103 Male, 53 Female)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 1: Upload Your Dataset\n",
    "\n",
    "**Upload `Metric_Final.xlsx` file to Colab**\n",
    "\n",
    "Click the folder icon on the left ‚Üí Upload button ‚Üí Select file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ All packages installed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002570657E110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pandas/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000025708169390>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pandas/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000025708168AD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pandas/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000025708169D90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pandas/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002570816A510>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pandas/\n",
      "ERROR: Could not find a version that satisfies the requirement pandas (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python3.13t.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for pandas\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install -q pandas numpy scikit-learn matplotlib seaborn openpyxl joblib\n",
    "\n",
    "print(\"‚úÖ All packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 2: Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel('Metric_Final.xlsx')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"\\nüìã First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nüéØ Gender Distribution:\")\n",
    "print(df['Gender'].value_counts())\n",
    "print(f\"\\nPercentage:\")\n",
    "print(df['Gender'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 3: Data Preprocessing\n",
    "\n",
    "**Removing S. No. and ID No. - Using only 15 mandibular measurements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target - EXCLUDE S. No. and ID No.\n",
    "target_col = 'Gender'\n",
    "exclude_cols = ['S. No.', 'ID No.', 'Gender']\n",
    "X = df.drop(columns=exclude_cols)\n",
    "y = df[target_col]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURES USED (15 MANDIBULAR MEASUREMENTS)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úì Total Features: {len(X.columns)}\\n\")\n",
    "for i, col in enumerate(X.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "print(f\"\\n‚úì Missing values handled\")\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(f\"‚úì Target encoded: {le.classes_} ‚Üí {np.unique(y_encoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 4: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úì Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"‚úì Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"‚úì Split ratio: 80% train, 20% test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 5: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE SCALING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úì Features scaled using StandardScaler\")\n",
    "print(f\"  ‚Ä¢ Mean ‚âà 0, Standard Deviation ‚âà 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Step 6: Train Multiple ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TRAINING 5 ML MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Model 1: SVM\n",
    "print(\"\\nüéØ [1/5] Training SVM...\")\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "svm_acc = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"   ‚úì Accuracy: {svm_acc:.4f} ({svm_acc*100:.2f}%)\")\n",
    "results['SVM'] = {'model': svm_model, 'accuracy': svm_acc, 'predictions': y_pred_svm}\n",
    "\n",
    "# Model 2: Random Forest\n",
    "print(\"\\nüå≤ [2/5] Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"   ‚úì Accuracy: {rf_acc:.4f} ({rf_acc*100:.2f}%)\")\n",
    "results['Random Forest'] = {'model': rf_model, 'accuracy': rf_acc, 'predictions': y_pred_rf}\n",
    "\n",
    "# Model 3: Logistic Regression\n",
    "print(\"\\nüìà [3/5] Training Logistic Regression...\")\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "lr_acc = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"   ‚úì Accuracy: {lr_acc:.4f} ({lr_acc*100:.2f}%)\")\n",
    "results['Logistic Regression'] = {'model': lr_model, 'accuracy': lr_acc, 'predictions': y_pred_lr}\n",
    "\n",
    "# Model 4: Decision Tree\n",
    "print(\"\\nüå≥ [4/5] Training Decision Tree...\")\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "dt_acc = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"   ‚úì Accuracy: {dt_acc:.4f} ({dt_acc*100:.2f}%)\")\n",
    "results['Decision Tree'] = {'model': dt_model, 'accuracy': dt_acc, 'predictions': y_pred_dt}\n",
    "\n",
    "# Model 5: Neural Network\n",
    "print(\"\\nüß† [5/5] Training Neural Network...\")\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_nn = nn_model.predict(X_test_scaled)\n",
    "nn_acc = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"   ‚úì Accuracy: {nn_acc:.4f} ({nn_acc*100:.2f}%)\")\n",
    "results['Neural Network'] = {'model': nn_model, 'accuracy': nn_acc, 'predictions': y_pred_nn}\n",
    "\n",
    "print(\"\\n‚úÖ All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 7: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame([\n",
    "    {'Model': name, 'Accuracy': data['accuracy']}\n",
    "    for name, data in results.items()\n",
    "]).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\")\n",
    "display(comparison_df)\n",
    "\n",
    "# Find best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "best_accuracy = comparison_df.iloc[0]['Accuracy']\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "print(f\"‚úÖ Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(comparison_df['Model'], comparison_df['Accuracy'], \n",
    "                color=['#2ecc71' if i == 0 else '#3498db' for i in range(len(comparison_df))])\n",
    "plt.xlabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "plt.title('Model Accuracy Comparison (15 Features)', fontsize=14, fontweight='bold')\n",
    "plt.xlim([0, 1])\n",
    "for i, (model, acc) in enumerate(zip(comparison_df['Model'], comparison_df['Accuracy'])):\n",
    "    plt.text(acc + 0.02, i, f'{acc:.3f}', va='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 8: Detailed Evaluation of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model predictions\n",
    "y_pred_best = results[best_model_name]['predictions']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"DETAILED EVALUATION: {best_model_name}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=le.classes_))\n",
    "\n",
    "print(\"\\nüéØ Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "print(cm)\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=['Female', 'Male'], yticklabels=['Female', 'Male'],\n",
    "            annot_kws={'size': 16, 'weight': 'bold'})\n",
    "plt.xlabel('Predicted Gender', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Actual Gender', fontsize=12, fontweight='bold')\n",
    "plt.title(f'Confusion Matrix - {best_model_name}\\nAccuracy: {best_accuracy*100:.2f}%',\n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 9: Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SAVING MODELS (15 FEATURES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model, 'best_model_15features.pkl')\n",
    "print(f\"\\n‚úì Best model saved: best_model_15features.pkl\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'scaler_15features.pkl')\n",
    "print(f\"‚úì Scaler saved: scaler_15features.pkl\")\n",
    "\n",
    "# Save label encoder\n",
    "joblib.dump(le, 'label_encoder_15features.pkl')\n",
    "print(f\"‚úì Label encoder saved: label_encoder_15features.pkl\")\n",
    "\n",
    "# Save feature names\n",
    "with open('feature_names_15.txt', 'w') as f:\n",
    "    for feature in X.columns:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "print(f\"‚úì Feature names saved: feature_names_15.txt\")\n",
    "\n",
    "# Save all models\n",
    "for model_name, model_data in results.items():\n",
    "    filename = f\"model_{model_name.replace(' ', '_').lower()}_15features.pkl\"\n",
    "    joblib.dump(model_data['model'], filename)\n",
    "    print(f\"‚úì {model_name} saved: {filename}\")\n",
    "\n",
    "print(\"\\n‚úÖ All models saved successfully!\")\n",
    "print(\"\\nüì• Download files from left sidebar (folder icon)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Step 10: Test with Custom Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender(measurements):\n",
    "    \"\"\"\n",
    "    Predict gender from 15 mandibular measurements\n",
    "    \n",
    "    Args:\n",
    "        measurements: List of 15 values (no Serial No. or ID)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with prediction and confidence\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    if len(measurements) != 15:\n",
    "        return {'error': f'Expected 15 measurements, got {len(measurements)}'}\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    input_data = np.array(measurements).reshape(1, -1)\n",
    "    \n",
    "    # Scale\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = best_model.predict(input_scaled)[0]\n",
    "    probabilities = best_model.predict_proba(input_scaled)[0]\n",
    "    \n",
    "    # Get label\n",
    "    gender = le.inverse_transform([prediction])[0]\n",
    "    confidence = max(probabilities) * 100\n",
    "    \n",
    "    return {\n",
    "        'gender': gender,\n",
    "        'confidence': f'{confidence:.2f}%',\n",
    "        'probabilities': {\n",
    "            'Female': f'{probabilities[0]*100:.2f}%',\n",
    "            'Male': f'{probabilities[1]*100:.2f}%'\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example: Test with sample measurements (15 values only)\n",
    "print(\"=\"*80)\n",
    "print(\"TESTING WITH CUSTOM INPUT (15 FEATURES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample_measurements = [\n",
    "    10.5,   # M1 Length\n",
    "    12.3,   # M2 Bicondylar breadth\n",
    "    0.85,   # M3 Mandibular index\n",
    "    9.8,    # M3 Bigonial breadth\n",
    "    3.2,    # M5 URB\n",
    "    3.1,    # M6 LRB\n",
    "    6.5,    # M7 CondRH\n",
    "    5.8,    # M8 CorRH\n",
    "    120,    # M9 Gonial angle\n",
    "    7.5,    # M10 Cor length\n",
    "    1.2,    # M11 Cor breadth\n",
    "    11.5,   # M12 C-C distance\n",
    "    4.2,    # M13 Inter cor distance\n",
    "    3.6,    # M14 Cor-Fr distance\n",
    "    4.8     # M15 Bimental breadth\n",
    "]\n",
    "\n",
    "print(f\"\\nüìù Input: {len(sample_measurements)} measurements\")\n",
    "result = predict_gender(sample_measurements)\n",
    "print(f\"\\nüéØ Prediction: {result['gender']}\")\n",
    "print(f\"‚úÖ Confidence: {result['confidence']}\")\n",
    "print(f\"\\nüìä Probabilities:\")\n",
    "for gender, prob in result['probabilities'].items():\n",
    "    print(f\"  ‚Ä¢ {gender}: {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 11: Download Models\n",
    "\n",
    "**Click the folder icon on the left sidebar**\n",
    "\n",
    "Download these files:\n",
    "- `best_model_15features.pkl`\n",
    "- `scaler_15features.pkl`\n",
    "- `label_encoder_15features.pkl`\n",
    "- `feature_names_15.txt`\n",
    "\n",
    "**You can now use these models locally or in your Flask API!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "**Features Used:** 15 mandibular measurements (No Serial No., No ID)  \n",
    "**Best Model:** Logistic Regression  \n",
    "**Accuracy:** 75.00%  \n",
    "**Dataset:** 156 samples  \n",
    "\n",
    "**Files Created:**\n",
    "- best_model_15features.pkl\n",
    "- scaler_15features.pkl\n",
    "- label_encoder_15features.pkl\n",
    "- feature_names_15.txt\n",
    "- All 5 model files\n",
    "\n",
    "**Team Metric Mind** | VTU CSE Project | 2024"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
